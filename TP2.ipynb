{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykPhRc6Dk6Jx"
      },
      "source": [
        "# TP2: Redes Neuronales 2\n",
        "### Francisco Mendizabal (61454)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfZ771blhgk"
      },
      "source": [
        "# Clasificación de texto\n",
        "\n",
        "Nada nuevo acá."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dvmO-ANtnKTv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import gensim\n",
        "import os, re, csv, math, codecs\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Configuración del sonido de alarma\n",
        "duration = 2     # Duración del sonido en segundos (ajusta según tus preferencias)\n",
        "frequency = 500  # Frecuencia en Hz (ajusta según el tono que desees)\n",
        "amplitude = 0.5  # Amplitud (volumen)\n",
        "\n",
        "# Generar el tono de alarma (en este caso, un tono sinusoidal)\n",
        "t = np.linspace(0, duration, int(duration * 44100), endpoint=False)\n",
        "signal = amplitude * np.sin(2 * np.pi * frequency * t)\n",
        "\n",
        "# Guardar el sonido en un archivo WAV\n",
        "output_file = \"alarm_sound.wav\"\n",
        "wavfile.write(output_file, 44100, signal.astype(np.float32))\n",
        "\n",
        "print(f\"Archivo de sonido '{output_file}' generado exitosamente.\")\n",
        "\n",
        "#Audio(\"alarm_sound.wav\", autoplay=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdppzEbEASvt",
        "outputId": "e99bac17-0030-403f-f8f8-3d9c7b960f9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo de sonido 'alarm_sound.wav' generado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ipzjoOmMRl",
        "outputId": "8212b56c-dc30-466b-ead1-b90ae42f9b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism',\n",
            " 'comp.graphics',\n",
            " 'comp.os.ms-windows.misc',\n",
            " 'comp.sys.ibm.pc.hardware',\n",
            " 'comp.sys.mac.hardware',\n",
            " 'comp.windows.x',\n",
            " 'misc.forsale',\n",
            " 'rec.autos',\n",
            " 'rec.motorcycles',\n",
            " 'rec.sport.baseball',\n",
            " 'rec.sport.hockey',\n",
            " 'sci.crypt',\n",
            " 'sci.electronics',\n",
            " 'sci.med',\n",
            " 'sci.space',\n",
            " 'soc.religion.christian',\n",
            " 'talk.politics.guns',\n",
            " 'talk.politics.mideast',\n",
            " 'talk.politics.misc',\n",
            " 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(newsgroups_train.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPPn0oK0k6J3",
        "outputId": "5a29ede7-3a95-43d3-9aff-178181a9eb6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([7, 4, 4, ..., 3, 1, 8])\n"
          ]
        }
      ],
      "source": [
        "pprint(newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PVbAh-fnP4E",
        "outputId": "48080bf4-7545-4e6b-c1d1-0f262027df5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: ab@nova.cc.purdue.edu (Allen B)\n",
            "Subject: Re: TIFF: philosophical significance of 42\n",
            "Organization: Purdue University\n",
            "Lines: 39\n",
            "\n",
            "In article <prestonm.735400848@cs.man.ac.uk> prestonm@cs.man.ac.uk (Martin  \n",
            "Preston) writes:\n",
            "> Why not use the PD C library for reading/writing TIFF files? It took me a\n",
            "> good 20 minutes to start using them in your own app.\n",
            "\n",
            "I certainly do use it whenever I have to do TIFF, and it usually works\n",
            "very well.  That's not my point.  I'm >philosophically< opposed to it\n",
            "because of its complexity.\n",
            "\n",
            "This complexity has led to some programs' poor TIFF writers making\n",
            "some very bizarre files, other programs' inability to load TIFF\n",
            "images (though they'll save them, of course), and a general\n",
            "inability to interchange images between different environments\n",
            "despite the fact they all think they understand TIFF.\n",
            "\n",
            "As the saying goes, \"It's not me I'm worried about- it's all the\n",
            ">other<  assholes out there!\"  I've had big trouble with misuse and\n",
            "abuse of TIFF over the years, and I chalk it all up to the immense (and\n",
            "unnecessary) complexity of the format.\n",
            "\n",
            "In the words of the TIFF 5.0 spec, Appendix G, page G-1 (capitalized\n",
            "emphasis mine):\n",
            "\n",
            "\"The only problem with this sort of success is that TIFF was designed\n",
            "to be powerful and flexible, at the expense of simplicity.  It takes a\n",
            "fair amount of effort to handle all the options currently defined in\n",
            "this specification (PROBABLY NO APPLICATION DOES A COMPLETE JOB),\n",
            "and that is currently the only way you can be >sure< that you will be\n",
            "able to import any TIFF image, since there are so many\n",
            "image-generating applications out there now.\"\n",
            "\n",
            "\n",
            "If a program (or worse all applications) can't read >every< TIFF\n",
            "image, that means there are some it won't- some that I might have to\n",
            "deal with.  Why would I want my images to be trapped in that format?  I\n",
            "don't and neither should anyone who agrees with my reasoning- not\n",
            "that anyone does, of course! :-)\n",
            "\n",
            "ab\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(newsgroups_train.data[16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vRBZtI2zoTT7"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer(num_words=30000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=\"UNK\", document_count=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ClA5L6pnpHP7"
      },
      "outputs": [],
      "source": [
        "token.fit_on_texts(newsgroups_train.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f1Wcf-ifpjjM"
      },
      "outputs": [],
      "source": [
        "train_sequences = token.texts_to_sequences(newsgroups_train.data)\n",
        "test_sequences = token.texts_to_sequences(newsgroups_test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2toIg26nN8d7",
        "outputId": "bb3a496e-6acc-4124-9906-15afeb95ce83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15,\n",
              " 1,\n",
              " 4309,\n",
              " 1351,\n",
              " 16,\n",
              " 11127,\n",
              " 39,\n",
              " 251,\n",
              " 30,\n",
              " 43,\n",
              " 299,\n",
              " 10,\n",
              " 18,\n",
              " 96,\n",
              " 79,\n",
              " 92,\n",
              " 23734,\n",
              " 4309,\n",
              " 1351,\n",
              " 16,\n",
              " 35,\n",
              " 78,\n",
              " 4,\n",
              " 2953,\n",
              " 611,\n",
              " 1768,\n",
              " 33,\n",
              " 212,\n",
              " 9,\n",
              " 27,\n",
              " 1309,\n",
              " 28,\n",
              " 172,\n",
              " 67,\n",
              " 48,\n",
              " 124,\n",
              " 9880,\n",
              " 64,\n",
              " 17,\n",
              " 18,\n",
              " 299,\n",
              " 9,\n",
              " 709,\n",
              " 2,\n",
              " 87,\n",
              " 264,\n",
              " 12,\n",
              " 27,\n",
              " 5,\n",
              " 37,\n",
              " 1498,\n",
              " 2267,\n",
              " 299,\n",
              " 1163,\n",
              " 3,\n",
              " 19,\n",
              " 15,\n",
              " 2,\n",
              " 1348,\n",
              " 13638,\n",
              " 844,\n",
              " 15449,\n",
              " 12,\n",
              " 27,\n",
              " 338,\n",
              " 5,\n",
              " 1,\n",
              " 2,\n",
              " 4018,\n",
              " 81,\n",
              " 183,\n",
              " 485,\n",
              " 8,\n",
              " 1377,\n",
              " 2,\n",
              " 845,\n",
              " 8165,\n",
              " 27,\n",
              " 1836,\n",
              " 15,\n",
              " 2,\n",
              " 817,\n",
              " 4,\n",
              " 2,\n",
              " 727,\n",
              " 18,\n",
              " 10,\n",
              " 45,\n",
              " 9,\n",
              " 89,\n",
              " 28,\n",
              " 172,\n",
              " 40,\n",
              " 1,\n",
              " 5,\n",
              " 829,\n",
              " 274,\n",
              " 1079,\n",
              " 2909,\n",
              " 199,\n",
              " 4,\n",
              " 2805,\n",
              " 154,\n",
              " 18,\n",
              " 299,\n",
              " 10,\n",
              " 240,\n",
              " 629,\n",
              " 26,\n",
              " 809,\n",
              " 358,\n",
              " 14,\n",
              " 22,\n",
              " 17,\n",
              " 18,\n",
              " 21901,\n",
              " 385,\n",
              " 299,\n",
              " 182,\n",
              " 113,\n",
              " 189,\n",
              " 207,\n",
              " 1499,\n",
              " 1342,\n",
              " 3,\n",
              " 14,\n",
              " 36,\n",
              " 59,\n",
              " 7861,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "ydWPszTep0dj",
        "outputId": "f90cc18e-9b3c-4309-f4cd-c728ca1ce378"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "lengths=[len(seq) for seq in train_sequences]\n",
        "lengths=dict(Counter(lengths))\n",
        "plt.figure(figsize=[24,6])\n",
        "plt.scatter(list(lengths.keys()), list(lengths.values()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jEiPTqOBT_V7"
      },
      "outputs": [],
      "source": [
        "max_len = 500\n",
        "train_sequences = pad_sequences(train_sequences, maxlen=max_len)\n",
        "test_sequences = pad_sequences(test_sequences, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJlUrLkfsBfK",
        "outputId": "e08fdc34-5565-4221-a85e-fcb95cb08d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,    15,     1,  4309,  1351,    16, 11127,    39,   251,\n",
              "          30,    43,   299,    10,    18,    96,    79,    92, 23734,\n",
              "        4309,  1351,    16,    35,    78,     4,  2953,   611,  1768,\n",
              "          33,   212,     9,    27,  1309,    28,   172,    67,    48,\n",
              "         124,  9880,    64,    17,    18,   299,     9,   709,     2,\n",
              "          87,   264,    12,    27,     5,    37,  1498,  2267,   299,\n",
              "        1163,     3,    19,    15,     2,  1348, 13638,   844, 15449,\n",
              "          12,    27,   338,     5,     1,     2,  4018,    81,   183,\n",
              "         485,     8,  1377,     2,   845,  8165,    27,  1836,    15,\n",
              "           2,   817,     4,     2,   727,    18,    10,    45,     9,\n",
              "          89,    28,   172,    40,     1,     5,   829,   274,  1079,\n",
              "        2909,   199,     4,  2805,   154,    18,   299,    10,   240,\n",
              "         629,    26,   809,   358,    14,    22,    17,    18, 21901,\n",
              "         385,   299,   182,   113,   189,   207,  1499,  1342,     3,\n",
              "          14,    36,    59,  7861,     1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4lY7mGCLUf0M"
      },
      "outputs": [],
      "source": [
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmflnp5NQF8g",
        "outputId": "c1c52f53-d5b2-4134-f873-ffee5399f632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'UNK',\n",
              " 2: 'the',\n",
              " 3: 'to',\n",
              " 4: 'of',\n",
              " 5: 'a',\n",
              " 6: \"'ax\",\n",
              " 7: 'and',\n",
              " 8: 'in',\n",
              " 9: 'i',\n",
              " 10: 'is',\n",
              " 11: 'that',\n",
              " 12: 'it',\n",
              " 13: 'for',\n",
              " 14: 'you',\n",
              " 15: 'from',\n",
              " 16: 'edu',\n",
              " 17: 'on',\n",
              " 18: 'this',\n",
              " 19: 'be',\n",
              " 20: 'are',\n",
              " 21: 'not',\n",
              " 22: 'have',\n",
              " 23: 'with',\n",
              " 24: 'as',\n",
              " 25: '1',\n",
              " 26: 'or',\n",
              " 27: 'was',\n",
              " 28: 'if',\n",
              " 29: 'but',\n",
              " 30: 'subject',\n",
              " 31: 'they',\n",
              " 32: 'com',\n",
              " 33: 'lines',\n",
              " 34: 'at',\n",
              " 35: 'organization',\n",
              " 36: 'by',\n",
              " 37: '2',\n",
              " 38: 'an',\n",
              " 39: 'my',\n",
              " 40: 'can',\n",
              " 41: 'x',\n",
              " 42: '3',\n",
              " 43: 'what',\n",
              " 44: '0',\n",
              " 45: 'all',\n",
              " 46: 'will',\n",
              " 47: 'm',\n",
              " 48: 'there',\n",
              " 49: 'would',\n",
              " 50: 'one',\n",
              " 51: 'do',\n",
              " 52: \"'\",\n",
              " 53: 'about',\n",
              " 54: 're',\n",
              " 55: 'we',\n",
              " 56: 'writes',\n",
              " 57: 'so',\n",
              " 58: 'he',\n",
              " 59: 'your',\n",
              " 60: 'no',\n",
              " 61: 'has',\n",
              " 62: 'article',\n",
              " 63: 'any',\n",
              " 64: 'me',\n",
              " 65: 'some',\n",
              " 66: 'who',\n",
              " 67: 'out',\n",
              " 68: 'which',\n",
              " 69: '4',\n",
              " 70: 'q',\n",
              " 71: 'more',\n",
              " 72: 'like',\n",
              " 73: 'people',\n",
              " 74: \"don't\",\n",
              " 75: 'when',\n",
              " 76: '5',\n",
              " 77: 'just',\n",
              " 78: 'university',\n",
              " 79: 'posting',\n",
              " 80: 'their',\n",
              " 81: 'were',\n",
              " 82: 'up',\n",
              " 83: 'r',\n",
              " 84: 'p',\n",
              " 85: 'w',\n",
              " 86: 'how',\n",
              " 87: 'other',\n",
              " 88: '7',\n",
              " 89: 'know',\n",
              " 90: 's',\n",
              " 91: 'only',\n",
              " 92: 'host',\n",
              " 93: 'get',\n",
              " 94: 'c',\n",
              " 95: 'them',\n",
              " 96: 'nntp',\n",
              " 97: 'max',\n",
              " 98: 'than',\n",
              " 99: 'had',\n",
              " 100: 'think',\n",
              " 101: 'g',\n",
              " 102: 'been',\n",
              " 103: 'his',\n",
              " 104: '8',\n",
              " 105: 'o',\n",
              " 106: 'also',\n",
              " 107: '6',\n",
              " 108: 'use',\n",
              " 109: 'does',\n",
              " 110: 'time',\n",
              " 111: 'new',\n",
              " 112: 'then',\n",
              " 113: 'e',\n",
              " 114: \"it's\",\n",
              " 115: 'good',\n",
              " 116: \"i'm\",\n",
              " 117: 'these',\n",
              " 118: 'd',\n",
              " 119: 'u',\n",
              " 120: 'should',\n",
              " 121: '9',\n",
              " 122: 'ca',\n",
              " 123: 'n',\n",
              " 124: 'could',\n",
              " 125: 'well',\n",
              " 126: 'us',\n",
              " 127: 'because',\n",
              " 128: 'am',\n",
              " 129: 'b',\n",
              " 130: 'may',\n",
              " 131: 't',\n",
              " 132: 'even',\n",
              " 133: 'why',\n",
              " 134: 'very',\n",
              " 135: 'now',\n",
              " 136: 'into',\n",
              " 137: 'see',\n",
              " 138: 'cs',\n",
              " 139: 'two',\n",
              " 140: 'way',\n",
              " 141: 'v',\n",
              " 142: 'first',\n",
              " 143: 'many',\n",
              " 144: 'those',\n",
              " 145: 'make',\n",
              " 146: 'much',\n",
              " 147: 'most',\n",
              " 148: 'system',\n",
              " 149: 'such',\n",
              " 150: 'distribution',\n",
              " 151: 'right',\n",
              " 152: 'say',\n",
              " 153: 'l',\n",
              " 154: 'where',\n",
              " 155: 'world',\n",
              " 156: 'god',\n",
              " 157: 'k',\n",
              " 158: 'z',\n",
              " 159: 'h',\n",
              " 160: 'want',\n",
              " 161: 'our',\n",
              " 162: 'here',\n",
              " 163: 'its',\n",
              " 164: 'go',\n",
              " 165: 'reply',\n",
              " 166: '10',\n",
              " 167: 'used',\n",
              " 168: 'said',\n",
              " 169: 'being',\n",
              " 170: 'did',\n",
              " 171: 'over',\n",
              " 172: 'anyone',\n",
              " 173: 'same',\n",
              " 174: 'after',\n",
              " 175: 'need',\n",
              " 176: 'work',\n",
              " 177: 'too',\n",
              " 178: 'state',\n",
              " 179: 'something',\n",
              " 180: 'problem',\n",
              " 181: 'j',\n",
              " 182: 'please',\n",
              " 183: 'really',\n",
              " 184: 'computer',\n",
              " 185: 'him',\n",
              " 186: 'off',\n",
              " 187: 'since',\n",
              " 188: 'f',\n",
              " 189: 'mail',\n",
              " 190: 'believe',\n",
              " 191: 'back',\n",
              " 192: 'still',\n",
              " 193: 'going',\n",
              " 194: 'file',\n",
              " 195: 'year',\n",
              " 196: 'information',\n",
              " 197: 'windows',\n",
              " 198: 'help',\n",
              " 199: 'years',\n",
              " 200: 'using',\n",
              " 201: 'find',\n",
              " 202: 'take',\n",
              " 203: 'question',\n",
              " 204: 'point',\n",
              " 205: 'last',\n",
              " 206: 'space',\n",
              " 207: 'thanks',\n",
              " 208: 'before',\n",
              " 209: 'must',\n",
              " 210: \"i've\",\n",
              " 211: 'never',\n",
              " 212: '15',\n",
              " 213: 'things',\n",
              " 214: 'better',\n",
              " 215: 'while',\n",
              " 216: '16',\n",
              " 217: 'news',\n",
              " 218: '20',\n",
              " 219: 'government',\n",
              " 220: 'might',\n",
              " 221: 'usa',\n",
              " 222: 'own',\n",
              " 223: \"can't\",\n",
              " 224: 'both',\n",
              " 225: 'number',\n",
              " 226: 'read',\n",
              " 227: 'sure',\n",
              " 228: 'program',\n",
              " 229: 'another',\n",
              " 230: 'case',\n",
              " 231: 'without',\n",
              " 232: 'etc',\n",
              " 233: 'key',\n",
              " 234: 'david',\n",
              " 235: 'data',\n",
              " 236: 'down',\n",
              " 237: 'through',\n",
              " 238: 'got',\n",
              " 239: 'y',\n",
              " 240: 'made',\n",
              " 241: '14',\n",
              " 242: 'drive',\n",
              " 243: 'software',\n",
              " 244: 'bit',\n",
              " 245: '1993',\n",
              " 246: 'long',\n",
              " 247: 'available',\n",
              " 248: 'law',\n",
              " 249: 'under',\n",
              " 250: '00',\n",
              " 251: 'thing',\n",
              " 252: '12',\n",
              " 253: 'someone',\n",
              " 254: \"doesn't\",\n",
              " 255: 'power',\n",
              " 256: 'look',\n",
              " 257: 'part',\n",
              " 258: 'uk',\n",
              " 259: 'between',\n",
              " 260: 'few',\n",
              " 261: 'little',\n",
              " 262: 'version',\n",
              " 263: 'come',\n",
              " 264: 'day',\n",
              " 265: \"that's\",\n",
              " 266: \"didn't\",\n",
              " 267: 'however',\n",
              " 268: '25',\n",
              " 269: 'each',\n",
              " 270: 'public',\n",
              " 271: 'org',\n",
              " 272: 'anything',\n",
              " 273: 'around',\n",
              " 274: 'name',\n",
              " 275: 'fact',\n",
              " 276: 'science',\n",
              " 277: 'give',\n",
              " 278: 'john',\n",
              " 279: 'cc',\n",
              " 280: 'access',\n",
              " 281: 'every',\n",
              " 282: 'best',\n",
              " 283: 'true',\n",
              " 284: 'probably',\n",
              " 285: 'again',\n",
              " 286: '17',\n",
              " 287: '11',\n",
              " 288: 'line',\n",
              " 289: '30',\n",
              " 290: 'research',\n",
              " 291: 'gov',\n",
              " 292: 'against',\n",
              " 293: 'nasa',\n",
              " 294: 'course',\n",
              " 295: 'least',\n",
              " 296: 'tell',\n",
              " 297: 'set',\n",
              " 298: 'seems',\n",
              " 299: 'car',\n",
              " 300: 'different',\n",
              " 301: 'group',\n",
              " 302: 'list',\n",
              " 303: 'great',\n",
              " 304: 'systems',\n",
              " 305: 'put',\n",
              " 306: 'enough',\n",
              " 307: 'run',\n",
              " 308: 'high',\n",
              " 309: 'try',\n",
              " 310: '24',\n",
              " 311: 'hard',\n",
              " 312: 'lot',\n",
              " 313: 'ac',\n",
              " 314: 'real',\n",
              " 315: 'says',\n",
              " 316: 'second',\n",
              " 317: '18',\n",
              " 318: 'life',\n",
              " 319: 'mr',\n",
              " 320: 'far',\n",
              " 321: '13',\n",
              " 322: 'old',\n",
              " 323: 'net',\n",
              " 324: 'possible',\n",
              " 325: 'g9v',\n",
              " 326: 'actually',\n",
              " 327: 'either',\n",
              " 328: 'end',\n",
              " 329: 'post',\n",
              " 330: 'game',\n",
              " 331: 'though',\n",
              " 332: 'support',\n",
              " 333: 'gun',\n",
              " 334: 'inc',\n",
              " 335: 'technology',\n",
              " 336: 'card',\n",
              " 337: 'b8f',\n",
              " 338: 'called',\n",
              " 339: 'her',\n",
              " 340: 'she',\n",
              " 341: 'de',\n",
              " 342: \"i'd\",\n",
              " 343: 'sun',\n",
              " 344: 'free',\n",
              " 345: 'rather',\n",
              " 346: 'center',\n",
              " 347: 'window',\n",
              " 348: 'email',\n",
              " 349: 'nothing',\n",
              " 350: 'internet',\n",
              " 351: '19',\n",
              " 352: 'next',\n",
              " 353: 'non',\n",
              " 354: 'team',\n",
              " 355: 'chip',\n",
              " 356: 'mean',\n",
              " 357: 'jesus',\n",
              " 358: 'info',\n",
              " 359: 'let',\n",
              " 360: 'problems',\n",
              " 361: \"you're\",\n",
              " 362: 'call',\n",
              " 363: 'wrong',\n",
              " 364: 'keep',\n",
              " 365: 'files',\n",
              " 366: 'send',\n",
              " 367: 'based',\n",
              " 368: 'apr',\n",
              " 369: '50',\n",
              " 370: 'message',\n",
              " 371: 'bad',\n",
              " 372: 'mark',\n",
              " 373: 'order',\n",
              " 374: 'example',\n",
              " 375: 'reason',\n",
              " 376: 'a86',\n",
              " 377: 'yes',\n",
              " 378: 'having',\n",
              " 379: 'done',\n",
              " 380: 'found',\n",
              " 381: 'maybe',\n",
              " 382: 'able',\n",
              " 383: 'else',\n",
              " 384: 'netcom',\n",
              " 385: 'looking',\n",
              " 386: '21',\n",
              " 387: 'above',\n",
              " 388: 'man',\n",
              " 389: 'national',\n",
              " 390: 'person',\n",
              " 391: 'control',\n",
              " 392: 'thought',\n",
              " 393: \"isn't\",\n",
              " 394: 'three',\n",
              " 395: 'ibm',\n",
              " 396: 'hp',\n",
              " 397: 'always',\n",
              " 398: 'less',\n",
              " 399: 'mit',\n",
              " 400: 'place',\n",
              " 401: 'others',\n",
              " 402: '145',\n",
              " 403: 'following',\n",
              " 404: 'left',\n",
              " 405: 'times',\n",
              " 406: '22',\n",
              " 407: 'doing',\n",
              " 408: 'general',\n",
              " 409: 'bill',\n",
              " 410: 'scsi',\n",
              " 411: 'several',\n",
              " 412: 'keywords',\n",
              " 413: 'trying',\n",
              " 414: 'code',\n",
              " 415: 'seen',\n",
              " 416: 'dos',\n",
              " 417: '000',\n",
              " 418: 'uucp',\n",
              " 419: 'heard',\n",
              " 420: 'graphics',\n",
              " 421: 'yet',\n",
              " 422: 'american',\n",
              " 423: 'ever',\n",
              " 424: 'means',\n",
              " 425: 'home',\n",
              " 426: '93',\n",
              " 427: 'christian',\n",
              " 428: 'quite',\n",
              " 429: 'phone',\n",
              " 430: 'away',\n",
              " 431: 'once',\n",
              " 432: 'big',\n",
              " 433: 'questions',\n",
              " 434: 'israel',\n",
              " 435: 'note',\n",
              " 436: 'wrote',\n",
              " 437: 'win',\n",
              " 438: 'opinions',\n",
              " 439: 'given',\n",
              " 440: 'steve',\n",
              " 441: 'idea',\n",
              " 442: 'washington',\n",
              " 443: 'mac',\n",
              " 444: 'getting',\n",
              " 445: 'start',\n",
              " 446: 'play',\n",
              " 447: 'source',\n",
              " 448: '23',\n",
              " 449: 'whether',\n",
              " 450: 'human',\n",
              " 451: 'jews',\n",
              " 452: 'during',\n",
              " 453: 'pc',\n",
              " 454: '40',\n",
              " 455: 'today',\n",
              " 456: 'book',\n",
              " 457: 'standard',\n",
              " 458: 'michael',\n",
              " 459: 'kind',\n",
              " 460: 'current',\n",
              " 461: 'remember',\n",
              " 462: 'encryption',\n",
              " 463: 'money',\n",
              " 464: 'already',\n",
              " 465: 'ftp',\n",
              " 466: 'pl',\n",
              " 467: \"i'll\",\n",
              " 468: 'seem',\n",
              " 469: 'au',\n",
              " 470: 'cannot',\n",
              " 471: 'local',\n",
              " 472: 'disk',\n",
              " 473: 'image',\n",
              " 474: 'until',\n",
              " 475: 'makes',\n",
              " 476: 'ask',\n",
              " 477: 'andrew',\n",
              " 478: 'games',\n",
              " 479: 'large',\n",
              " 480: 'co',\n",
              " 481: 'evidence',\n",
              " 482: '32',\n",
              " 483: 'department',\n",
              " 484: 'address',\n",
              " 485: 'small',\n",
              " 486: 'word',\n",
              " 487: 'fax',\n",
              " 488: 'speed',\n",
              " 489: 'president',\n",
              " 490: 'apple',\n",
              " 491: 'change',\n",
              " 492: 'ago',\n",
              " 493: '27',\n",
              " 494: 'institute',\n",
              " 495: 'clipper',\n",
              " 496: 'perhaps',\n",
              " 497: '34',\n",
              " 498: 'answer',\n",
              " 499: 'mike',\n",
              " 500: 'jim',\n",
              " 501: 'bible',\n",
              " 502: 'told',\n",
              " 503: 'issue',\n",
              " 504: 'open',\n",
              " 505: 'running',\n",
              " 506: 'price',\n",
              " 507: 'memory',\n",
              " 508: 'full',\n",
              " 509: 'works',\n",
              " 510: 'came',\n",
              " 511: 'robert',\n",
              " 512: 'hand',\n",
              " 513: 'unix',\n",
              " 514: 'rights',\n",
              " 515: 'whole',\n",
              " 516: 'children',\n",
              " 517: 'sale',\n",
              " 518: '26',\n",
              " 519: 'buy',\n",
              " 520: 'april',\n",
              " 521: 'interested',\n",
              " 522: '100',\n",
              " 523: 'pretty',\n",
              " 524: 'type',\n",
              " 525: 'uiuc',\n",
              " 526: 'server',\n",
              " 527: 'stuff',\n",
              " 528: 'live',\n",
              " 529: 'turkish',\n",
              " 530: 'hope',\n",
              " 531: 'show',\n",
              " 532: 'states',\n",
              " 533: \"there's\",\n",
              " 534: 'days',\n",
              " 535: 'color',\n",
              " 536: 'paul',\n",
              " 537: 'side',\n",
              " 538: 'saying',\n",
              " 539: 'vs',\n",
              " 540: 'everything',\n",
              " 541: 'war',\n",
              " 542: 'important',\n",
              " 543: 'armenian',\n",
              " 544: 'canada',\n",
              " 545: 'original',\n",
              " 546: '28',\n",
              " 547: 'oh',\n",
              " 548: 'check',\n",
              " 549: 'went',\n",
              " 550: 'toronto',\n",
              " 551: '1d9',\n",
              " 552: 'box',\n",
              " 553: 'matter',\n",
              " 554: 'machine',\n",
              " 555: 'agree',\n",
              " 556: 'video',\n",
              " 557: '0d',\n",
              " 558: 'cost',\n",
              " 559: 'white',\n",
              " 560: 'israeli',\n",
              " 561: 'often',\n",
              " 562: 'including',\n",
              " 563: 'comes',\n",
              " 564: 'christians',\n",
              " 565: 'area',\n",
              " 566: 'feel',\n",
              " 567: 'faq',\n",
              " 568: 'everyone',\n",
              " 569: 'almost',\n",
              " 570: 'house',\n",
              " 571: 'colorado',\n",
              " 572: 'simply',\n",
              " 573: 'wanted',\n",
              " 574: 'understand',\n",
              " 575: 'ms',\n",
              " 576: \"won't\",\n",
              " 577: 'later',\n",
              " 578: 'output',\n",
              " 579: 'security',\n",
              " 580: 'programs',\n",
              " 581: 'care',\n",
              " 582: \"wouldn't\",\n",
              " 583: 'hockey',\n",
              " 584: 'display',\n",
              " 585: 'engineering',\n",
              " 586: 'love',\n",
              " 587: 'single',\n",
              " 588: 'include',\n",
              " 589: 'working',\n",
              " 590: 'dept',\n",
              " 591: 'low',\n",
              " 592: 'cmu',\n",
              " 593: 'mind',\n",
              " 594: 'service',\n",
              " 595: 'claim',\n",
              " 596: 'st',\n",
              " 597: 'db',\n",
              " 598: 'although',\n",
              " 599: 'instead',\n",
              " 600: 'top',\n",
              " 601: 'certainly',\n",
              " 602: 'hi',\n",
              " 603: 'truth',\n",
              " 604: 'write',\n",
              " 605: 'ohio',\n",
              " 606: 'ok',\n",
              " 607: 'church',\n",
              " 608: 'anyway',\n",
              " 609: 'california',\n",
              " 610: 'school',\n",
              " 611: 'college',\n",
              " 612: 'consider',\n",
              " 613: '45',\n",
              " 614: '31',\n",
              " 615: '34u',\n",
              " 616: 'size',\n",
              " 617: 'guess',\n",
              " 618: 'season',\n",
              " 619: 'started',\n",
              " 620: 'anybody',\n",
              " 621: 'known',\n",
              " 622: 'provide',\n",
              " 623: 'hell',\n",
              " 624: 'armenians',\n",
              " 625: 'religion',\n",
              " 626: 'contact',\n",
              " 627: 'package',\n",
              " 628: 'men',\n",
              " 629: 'history',\n",
              " 630: 'unless',\n",
              " 631: 'division',\n",
              " 632: 'making',\n",
              " 633: 'city',\n",
              " 634: 'tried',\n",
              " 635: 'earth',\n",
              " 636: 'keys',\n",
              " 637: 'san',\n",
              " 638: '33',\n",
              " 639: 'cause',\n",
              " 640: 'country',\n",
              " 641: 'network',\n",
              " 642: 'death',\n",
              " 643: 'james',\n",
              " 644: 'similar',\n",
              " 645: 'summary',\n",
              " 646: 'newsreader',\n",
              " 647: 'talk',\n",
              " 648: 'jewish',\n",
              " 649: 'fast',\n",
              " 650: 'hardware',\n",
              " 651: 'certain',\n",
              " 652: 'services',\n",
              " 653: '80',\n",
              " 654: 'difference',\n",
              " 655: 'user',\n",
              " 656: 'private',\n",
              " 657: 'level',\n",
              " 658: 'couple',\n",
              " 659: 'players',\n",
              " 660: 'company',\n",
              " 661: 'numbers',\n",
              " 662: 'took',\n",
              " 663: 'na',\n",
              " 664: 'black',\n",
              " 665: '29',\n",
              " 666: 'sort',\n",
              " 667: 'screen',\n",
              " 668: 'pub',\n",
              " 669: 'within',\n",
              " 670: 'faith',\n",
              " 671: 'major',\n",
              " 672: 'view',\n",
              " 673: 'police',\n",
              " 674: 'clinton',\n",
              " 675: 'likely',\n",
              " 676: \"he's\",\n",
              " 677: '0t',\n",
              " 678: 'per',\n",
              " 679: 'correct',\n",
              " 680: 'argument',\n",
              " 681: 'nice',\n",
              " 682: '35',\n",
              " 683: 'talking',\n",
              " 684: 'columbia',\n",
              " 685: 'cx',\n",
              " 686: 'via',\n",
              " 687: 'berkeley',\n",
              " 688: 'pitt',\n",
              " 689: \"they're\",\n",
              " 690: 'driver',\n",
              " 691: 'bike',\n",
              " 692: 'asked',\n",
              " 693: 'pay',\n",
              " 694: 'health',\n",
              " 695: 'dave',\n",
              " 696: 'ma',\n",
              " 697: 'york',\n",
              " 698: 'guns',\n",
              " 699: 'text',\n",
              " 700: 'application',\n",
              " 701: 'board',\n",
              " 702: 'usually',\n",
              " 703: 'experience',\n",
              " 704: 'press',\n",
              " 705: '55',\n",
              " 706: 'virginia',\n",
              " 707: 'exactly',\n",
              " 708: 'period',\n",
              " 709: 'saw',\n",
              " 710: 'cwru',\n",
              " 711: 'words',\n",
              " 712: 'keith',\n",
              " 713: 'especially',\n",
              " 714: 'sense',\n",
              " 715: 'sound',\n",
              " 716: 'groups',\n",
              " 717: 'points',\n",
              " 718: 'simple',\n",
              " 719: 'al',\n",
              " 720: 'themselves',\n",
              " 721: 'sorry',\n",
              " 722: 'att',\n",
              " 723: 'reading',\n",
              " 724: 'office',\n",
              " 725: 'copy',\n",
              " 726: \"we're\",\n",
              " 727: 'body',\n",
              " 728: 'gmt',\n",
              " 729: 'stop',\n",
              " 730: 'test',\n",
              " 731: 'deal',\n",
              " 732: 'killed',\n",
              " 733: 'brian',\n",
              " 734: 'dod',\n",
              " 735: 'comp',\n",
              " 736: 'head',\n",
              " 737: 'drivers',\n",
              " 738: '1992',\n",
              " 739: 'dead',\n",
              " 740: 'light',\n",
              " 741: 'needed',\n",
              " 742: 'clear',\n",
              " 743: 'self',\n",
              " 744: 'third',\n",
              " 745: '75u',\n",
              " 746: 'uses',\n",
              " 747: 'goes',\n",
              " 748: 'mode',\n",
              " 749: 'taken',\n",
              " 750: 'posted',\n",
              " 751: 'written',\n",
              " 752: 'bus',\n",
              " 753: 'common',\n",
              " 754: 'pittsburgh',\n",
              " 755: 'radio',\n",
              " 756: 'except',\n",
              " 757: 'business',\n",
              " 758: 'tin',\n",
              " 759: 'thus',\n",
              " 760: 'christ',\n",
              " 761: 'western',\n",
              " 762: 'fine',\n",
              " 763: '3t',\n",
              " 764: 'value',\n",
              " 765: 'turn',\n",
              " 766: 'short',\n",
              " 767: 'opinion',\n",
              " 768: 'week',\n",
              " 769: 'usenet',\n",
              " 770: 'advance',\n",
              " 771: 'communications',\n",
              " 772: 'young',\n",
              " 773: 'return',\n",
              " 774: 'exist',\n",
              " 775: 'myself',\n",
              " 776: 'air',\n",
              " 777: 'become',\n",
              " 778: 'bob',\n",
              " 779: 'force',\n",
              " 780: 'position',\n",
              " 781: 'guy',\n",
              " 782: 'mouse',\n",
              " 783: 'build',\n",
              " 784: 'se',\n",
              " 785: 'political',\n",
              " 786: 'among',\n",
              " 787: 'os',\n",
              " 788: 'happened',\n",
              " 789: '2di',\n",
              " 790: 'stanford',\n",
              " 791: 'easy',\n",
              " 792: 'laws',\n",
              " 793: 'form',\n",
              " 794: 'mine',\n",
              " 795: 'society',\n",
              " 796: 'smith',\n",
              " 797: 'runs',\n",
              " 798: 'particular',\n",
              " 799: 'anti',\n",
              " 800: 'discussion',\n",
              " 801: 'cleveland',\n",
              " 802: 'monitor',\n",
              " 803: 'sci',\n",
              " 804: 'motif',\n",
              " 805: 'four',\n",
              " 806: 'date',\n",
              " 807: 'peter',\n",
              " 808: 'ed',\n",
              " 809: 'whatever',\n",
              " 810: 'fire',\n",
              " 811: 'corporation',\n",
              " 812: 'built',\n",
              " 813: 'drives',\n",
              " 814: '04',\n",
              " 815: 'hear',\n",
              " 816: 'interesting',\n",
              " 817: 'rest',\n",
              " 818: 'therefore',\n",
              " 819: \"let's\",\n",
              " 820: 'needs',\n",
              " 821: '41',\n",
              " 822: 'military',\n",
              " 823: 'books',\n",
              " 824: 'hit',\n",
              " 825: 'league',\n",
              " 826: 'rate',\n",
              " 827: 'study',\n",
              " 828: 'night',\n",
              " 829: 'model',\n",
              " 830: \"haven't\",\n",
              " 831: 'lost',\n",
              " 832: 'gets',\n",
              " 833: 'considered',\n",
              " 834: 'face',\n",
              " 835: 'request',\n",
              " 836: 'future',\n",
              " 837: 'past',\n",
              " 838: '44',\n",
              " 839: \"what's\",\n",
              " 840: 'east',\n",
              " 841: 'situation',\n",
              " 842: 'itself',\n",
              " 843: 'strong',\n",
              " 844: 'early',\n",
              " 845: 'front',\n",
              " 846: 'cars',\n",
              " 847: 'statement',\n",
              " 848: 'job',\n",
              " 849: 'bhj',\n",
              " 850: 'special',\n",
              " 851: 'red',\n",
              " 852: 'texas',\n",
              " 853: 'ground',\n",
              " 854: 'longer',\n",
              " 855: 'la',\n",
              " 856: 'anonymous',\n",
              " 857: 'crime',\n",
              " 858: 'women',\n",
              " 859: 'section',\n",
              " 860: 'manager',\n",
              " 861: 'ones',\n",
              " 862: \"aren't\",\n",
              " 863: 'personal',\n",
              " 864: 'scott',\n",
              " 865: 'thinking',\n",
              " 866: \"wasn't\",\n",
              " 867: 'effect',\n",
              " 868: 'users',\n",
              " 869: 'kill',\n",
              " 870: '36',\n",
              " 871: 'weapons',\n",
              " 872: 'acs',\n",
              " 873: 'due',\n",
              " 874: 'add',\n",
              " 875: 'water',\n",
              " 876: 'plus',\n",
              " 877: 'sell',\n",
              " 878: 'policy',\n",
              " 879: 'act',\n",
              " 880: 'upon',\n",
              " 881: 'looks',\n",
              " 882: 'chicago',\n",
              " 883: 'road',\n",
              " 884: 'baseball',\n",
              " 885: 'cd',\n",
              " 886: 'ii',\n",
              " 887: '60',\n",
              " 888: 'sometimes',\n",
              " 889: 'format',\n",
              " 890: 'cso',\n",
              " 891: 'caltech',\n",
              " 892: 'series',\n",
              " 893: 'offer',\n",
              " 894: 'process',\n",
              " 895: 'error',\n",
              " 896: 'assume',\n",
              " 897: 'members',\n",
              " 898: 'defense',\n",
              " 899: 'disclaimer',\n",
              " 900: 'entry',\n",
              " 901: 'specific',\n",
              " 902: 'federal',\n",
              " 903: 'project',\n",
              " 904: 'tom',\n",
              " 905: 'coming',\n",
              " 906: 'recently',\n",
              " 907: 'sgi',\n",
              " 908: 'legal',\n",
              " 909: '38',\n",
              " 910: 'richard',\n",
              " 911: 'includes',\n",
              " 912: 'religious',\n",
              " 913: 'accept',\n",
              " 914: 'peace',\n",
              " 915: 'soon',\n",
              " 916: 'worth',\n",
              " 917: 'media',\n",
              " 918: 'united',\n",
              " 919: 'voice',\n",
              " 920: 'privacy',\n",
              " 921: 'ram',\n",
              " 922: 'rutgers',\n",
              " 923: 'nor',\n",
              " 924: 'behind',\n",
              " 925: 'taking',\n",
              " 926: 'controller',\n",
              " 927: 'bitnet',\n",
              " 928: 'tv',\n",
              " 929: 'food',\n",
              " 930: 'happen',\n",
              " 931: 'frank',\n",
              " 932: 'according',\n",
              " 933: 'near',\n",
              " 934: 'cases',\n",
              " 935: 'along',\n",
              " 936: 'together',\n",
              " 937: 'technical',\n",
              " 938: 'further',\n",
              " 939: 'moral',\n",
              " 940: 'giz',\n",
              " 941: 'international',\n",
              " 942: 'comments',\n",
              " 943: 'related',\n",
              " 944: 'purpose',\n",
              " 945: 'total',\n",
              " 946: 'cut',\n",
              " 947: 'allow',\n",
              " 948: 'parts',\n",
              " 949: 'fbi',\n",
              " 950: 'move',\n",
              " 951: 'corp',\n",
              " 952: 'fi',\n",
              " 953: 'explain',\n",
              " 954: 'expect',\n",
              " 955: 'performance',\n",
              " 956: 'land',\n",
              " 957: 'austin',\n",
              " 958: 'previous',\n",
              " 959: 'sources',\n",
              " 960: 'knowledge',\n",
              " 961: 'design',\n",
              " 962: 'months',\n",
              " 963: 'action',\n",
              " 964: 'mentioned',\n",
              " 965: 'dr',\n",
              " 966: 'result',\n",
              " 967: 'half',\n",
              " 968: 'math',\n",
              " 969: 'uunet',\n",
              " 970: 'friend',\n",
              " 971: 'ny',\n",
              " 972: 'medical',\n",
              " 973: '42',\n",
              " 974: 'court',\n",
              " 975: 'various',\n",
              " 976: 'utexas',\n",
              " 977: 'thomas',\n",
              " 978: 'building',\n",
              " 979: 'close',\n",
              " 980: 'necessary',\n",
              " 981: '02',\n",
              " 982: 'nhl',\n",
              " 983: '75',\n",
              " 984: 'reference',\n",
              " 985: 'images',\n",
              " 986: 'involved',\n",
              " 987: 'sent',\n",
              " 988: 'ide',\n",
              " 989: 'cover',\n",
              " 990: 'hold',\n",
              " 991: 'currently',\n",
              " 992: 'nl',\n",
              " 993: 'response',\n",
              " 994: 'himself',\n",
              " 995: 'million',\n",
              " 996: 'chris',\n",
              " 997: 'north',\n",
              " 998: 'machines',\n",
              " 999: 'rules',\n",
              " 1000: 'main',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "token.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yp9nq3GuKL8",
        "outputId": "08652f9e-fd5b-4d4d-b460-54bc6f0965d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "loading word embeddings...\n",
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "#load embeddings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "EMBEDDING_DIR = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(EMBEDDING_DIR + 'wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SDEVfp7RY489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce85cfd-823e-4452-9888-a11c148a1236"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.600e-02, -3.000e-04, -1.684e-01,  8.990e-02, -2.000e-02,\n",
              "       -9.300e-03,  4.820e-02, -3.080e-02, -4.510e-02,  6.000e-04,\n",
              "        1.680e-01,  9.650e-02,  3.061e-01, -4.110e-02,  2.960e-02,\n",
              "       -4.630e-02,  3.250e-02, -7.030e-02,  2.220e-02, -1.404e-01,\n",
              "       -2.638e-01, -1.340e-02,  1.277e-01,  1.227e-01,  1.803e-01,\n",
              "       -1.920e-02,  3.530e-02,  1.214e-01,  1.509e-01, -8.610e-02,\n",
              "        9.760e-02, -2.550e-02, -2.760e-02, -1.556e-01, -7.390e-02,\n",
              "        5.430e-02, -6.700e-02, -3.000e-03,  1.515e-01,  6.080e-02,\n",
              "        3.300e-02,  7.470e-02,  9.000e-04,  5.500e-02,  4.800e-03,\n",
              "       -1.320e-02, -2.620e-02, -1.804e-01,  8.050e-02,  4.640e-02,\n",
              "       -1.590e-02, -3.020e-02, -6.785e-01,  1.632e-01,  1.030e-02,\n",
              "        6.550e-02, -8.430e-02,  2.270e-02,  3.350e-02, -3.560e-02,\n",
              "       -6.380e-02, -1.111e-01, -1.700e-03,  9.780e-02,  5.650e-02,\n",
              "       -3.520e-02,  3.950e-02,  1.867e-01,  7.900e-02, -1.234e-01,\n",
              "        1.860e-02,  8.900e-02,  1.631e-01,  7.830e-02,  5.610e-02,\n",
              "        1.447e-01, -2.510e-02,  1.376e-01, -7.900e-03, -2.390e-02,\n",
              "        2.180e-02,  1.494e-01, -1.910e-02, -2.479e-01, -4.990e-02,\n",
              "        5.160e-02, -1.298e-01, -6.480e-02,  2.738e-01,  7.800e-03,\n",
              "        1.710e-02, -3.720e-02,  7.700e-02, -1.167e-01, -3.770e-02,\n",
              "       -4.320e-02,  1.860e-02,  2.090e-02, -1.670e-02,  3.450e-02,\n",
              "       -1.472e-01,  1.220e-02, -5.300e-02, -7.300e-03,  1.029e-01,\n",
              "        2.830e-02, -1.264e-01,  6.600e-03, -5.790e-02,  1.004e-01,\n",
              "       -1.225e-01,  2.470e-02,  8.080e-02, -3.990e-02, -1.080e-02,\n",
              "        4.300e-03,  1.840e-02,  4.880e-02, -1.740e-01, -3.181e-01,\n",
              "       -1.290e-01,  7.830e-02, -1.382e-01,  5.730e-02,  3.250e-02,\n",
              "        1.704e-01, -1.343e-01,  3.700e-03, -3.040e-02,  4.070e-02,\n",
              "        2.318e-01,  3.930e-02,  1.592e-01, -6.020e-02,  2.730e-02,\n",
              "        1.087e-01, -1.890e-02, -1.030e-01, -1.526e-01, -7.830e-02,\n",
              "       -1.257e-01,  1.261e-01, -8.320e-02,  1.561e-01, -2.254e-01,\n",
              "       -1.236e-01, -1.028e-01,  5.830e-02, -2.990e-02,  1.361e-01,\n",
              "       -4.360e-02, -1.580e-02, -1.210e-02,  1.076e-01, -1.770e-02,\n",
              "       -8.890e-02, -5.300e-03, -4.570e-02, -3.170e-02, -1.454e-01,\n",
              "       -1.237e-01, -8.860e-02, -1.620e-02, -1.603e-01,  5.050e-02,\n",
              "        1.500e-01,  6.970e-02, -7.150e-02, -2.450e-02, -9.900e-03,\n",
              "       -1.832e-01,  4.130e-02, -2.510e-02,  8.450e-02,  2.840e-02,\n",
              "       -1.314e-01,  3.021e-01, -1.812e-01, -7.380e-02, -9.990e-02,\n",
              "       -2.980e-02,  1.508e-01, -4.430e-02,  1.709e-01, -5.490e-02,\n",
              "       -1.333e-01, -4.600e-03,  3.950e-02, -2.540e-01, -6.960e-02,\n",
              "        1.900e-02, -4.140e-02,  7.290e-02,  5.560e-02, -9.210e-02,\n",
              "        9.860e-02,  4.900e-03, -1.271e-01,  9.580e-02, -1.140e-01,\n",
              "       -2.240e-02,  2.000e-02, -1.040e-02, -1.110e-02,  6.400e-03,\n",
              "        6.190e-02, -1.497e-01, -1.185e-01,  5.540e-02,  3.960e-02,\n",
              "        3.090e-02,  3.950e-02, -8.760e-02, -3.060e-02, -1.778e-01,\n",
              "        1.257e-01, -1.570e-01,  1.452e-01, -1.522e-01,  9.800e-03,\n",
              "        9.930e-02, -4.600e-03,  5.230e-02, -9.850e-02,  8.320e-02,\n",
              "       -2.352e-01,  2.050e-02,  1.426e-01, -8.500e-03, -3.160e-02,\n",
              "       -2.550e-02,  6.850e-02,  3.141e-01, -6.370e-02,  7.050e-02,\n",
              "       -1.557e-01, -2.177e-01,  1.380e-02, -2.602e-01,  4.350e-02,\n",
              "       -1.156e-01, -1.420e-02, -1.423e-01, -2.142e-01, -2.310e-02,\n",
              "       -7.290e-02,  1.277e-01, -1.052e-01, -1.444e-01,  4.128e-01,\n",
              "        1.017e-01, -1.077e-01,  7.220e-02, -6.290e-02, -9.490e-02,\n",
              "       -1.079e-01, -6.310e-02, -3.890e-02, -3.510e-02,  9.920e-02,\n",
              "        2.050e-02,  2.151e-01,  9.770e-02, -3.590e-02, -4.316e-01,\n",
              "        1.129e-01, -1.438e-01,  5.300e-03, -1.333e-01, -1.541e-01,\n",
              "        6.910e-02,  1.150e-01, -5.660e-02, -5.000e-03,  1.207e-01,\n",
              "       -6.110e-02, -4.740e-02, -1.151e-01, -2.870e-02,  1.378e-01,\n",
              "       -7.290e-02, -2.170e-02,  1.108e-01,  2.770e-02, -2.010e-02,\n",
              "       -2.236e-01, -1.250e-02, -6.930e-02,  2.340e-02, -2.140e-02,\n",
              "        6.940e-02, -5.070e-02, -5.490e-02, -9.270e-02,  7.020e-02,\n",
              "        1.719e-01, -1.370e-02,  6.800e-03,  1.336e-01,  2.860e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "embeddings_index[\"car\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DlY6kxXlUv_b"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP + Embeddings + Attention + CNN"
      ],
      "metadata": {
        "id": "SSmy9d_v0JR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se probaron todas las redes de la notebook. Debido a los resultados, y a lo solicitado en la consigna, las redes de mayor interés resultaron ser la red 3 \"TextCNN\" y la red 5 \"MLP + Embeddings + Attention + CNN\".\n",
        "\n",
        "La idea fue hacer una red con las características de ambas redes, es decir, la estructura general de la red 5, pero modificando las capas convolucionales, para obtener algo similar a la red 3.\n",
        "\n",
        "Antes de obtener la red final, se probó modificar algunos hiperpárametros para analizar su influencia sobre el resultado final:\n",
        "\n",
        "*   La red original tuvo un accuracy de 0.8405.\n",
        "*   Modificando la activación de la última capa convolucional por tanh, el accuracy disminuyó a 0.8299.\n",
        "*   Modificando el batch size a 16 y 64, no se observaron diferencias significativas, por lo cual se utilizó el valor de 64 para mayor velocidad de entrenamiento.\n",
        "*   Aumentar el tamaño de la capa densa a 200 no mostró diferencias significativas, por lo cual se mantuvo el valor de 100.\n",
        "*   Aumentar value_dim a 200, dio un accuracy de 0.8489.\n",
        "\n",
        "En definitiva, solo se hizo el último cambio a los hiperparámetros la red original. Se probo que value_dim=300 daba todavía mejores resultados, pero se optó por el valor de 200 debido a la demora en el entrenamiento.\n",
        "\n",
        "Lo siguiente fue fusionar las estructuras. Para ello, se reemplazo la primera capa convolucional por una serie de capas de distintos tamaños, que luego se concatenarían antes de la siguiente capa. Esto permite detectar patrones de distintos tamaños en el lenguaje, de la misma forma que lo hacíamos en imágenes.\n",
        "\n",
        "Se probaron:\n",
        "\n",
        "*   Capas de tamaños 2-4, logrando un accuracy de 0.8608.\n",
        "*   Capas de tamaños 2-8, logrando un accuracy de 0.8719.\n",
        "\n",
        "Por lo tanto, nos quedamos con la de mayor accuracy.\n"
      ],
      "metadata": {
        "id": "ffEHhaRLpcMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Reshape\n",
        "from keras.layers import Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, BatchNormalization, Activation\n",
        "import keras.backend as K\n",
        "from keras.activations import softmax\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "2L_z-i6V0Mpu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softMaxOverTime(x):\n",
        "    return softmax(x, axis=1)"
      ],
      "metadata": {
        "id": "DAYhYMo65QQ4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros\n",
        "value_dim = 200\n",
        "nb_words = num_words\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "\n",
        "K.clear_session()\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#conv_out = Conv1D(value_dim, 8, padding=\"same\")(embedding_layer)\n",
        "conv8 = Conv1D(value_dim, 8, activation='relu', padding='same')(embedding_layer)\n",
        "conv7 = Conv1D(value_dim, 7, activation='relu', padding='same')(embedding_layer)\n",
        "conv6 = Conv1D(value_dim, 6, activation='relu', padding='same')(embedding_layer)\n",
        "conv5 = Conv1D(value_dim, 5, activation='relu', padding='same')(embedding_layer)\n",
        "conv4 = Conv1D(value_dim, 4, activation='relu', padding='same')(embedding_layer)\n",
        "conv3 = Conv1D(value_dim, 3, activation='relu', padding='same')(embedding_layer)\n",
        "conv2 = Conv1D(value_dim, 2, activation='relu', padding='same')(embedding_layer)\n",
        "conv_out = Concatenate()([conv8, conv7, conv6, conv5, conv4, conv3, conv2])\n",
        "#conv_out = Concatenate()([conv4, conv3, conv2])\n",
        "conv_out = Activation(\"relu\")(conv_out)\n",
        "conv_out = Conv1D(value_dim, 8, activation=\"tanh\", padding=\"same\")(conv_out)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(conv_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, conv_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "dense1 = Dense(100, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(20, activation='softmax')(dense1)\n",
        "\n",
        "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
      ],
      "metadata": {
        "id": "0jW-fccq5U9n"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_layer, dense2)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUfjp0ny5YXp",
        "outputId": "5f25ba06-9da0-4ec1-e002-cccf0ad629f8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 500)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 500, 300)             4024320   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 500, 200)             480200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 500, 200)             420200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 500, 200)             360200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 500, 200)             300200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 500, 200)             240200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 500, 200)             180200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 500, 200)             120200    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 500, 1400)            0         ['conv1d[0][0]',              \n",
            "                                                                     'conv1d_1[0][0]',            \n",
            "                                                                     'conv1d_2[0][0]',            \n",
            "                                                                     'conv1d_3[0][0]',            \n",
            "                                                                     'conv1d_4[0][0]',            \n",
            "                                                                     'conv1d_5[0][0]',            \n",
            "                                                                     'conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 500, 1400)            0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 500, 200)             2240200   ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 500, 1)               201       ['conv1d_7[0][0]']            \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 500, 1)               0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, 500, 200, 1)          0         ['activation_1[0][0]']        \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 500, 200)             0         ['time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 500, 200)             0         ['reshape[0][0]',             \n",
            "                                                                     'conv1d_7[0][0]']            \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 200)                  0         ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 100)                  20100     ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 20)                   2020      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 44607121 (170.16 MB)\n",
            "Trainable params: 4363921 (16.65 MB)\n",
            "Non-trainable params: 40243200 (153.52 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_sequences, newsgroups_train.target, batch_size=64, epochs=100, validation_split=0.2, callbacks=early_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm_HGJzc5h32",
        "outputId": "3f3f59a8-7e01-4835-cde2-cc6a1b9020e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "142/142 [==============================] - 35s 217ms/step - loss: 1.9715 - accuracy: 0.3643 - val_loss: 0.9398 - val_accuracy: 0.6947\n",
            "Epoch 2/100\n",
            "142/142 [==============================] - 31s 216ms/step - loss: 0.6923 - accuracy: 0.7749 - val_loss: 0.6504 - val_accuracy: 0.8020\n",
            "Epoch 3/100\n",
            "142/142 [==============================] - 31s 215ms/step - loss: 0.4222 - accuracy: 0.8668 - val_loss: 0.5992 - val_accuracy: 0.8250\n",
            "Epoch 4/100\n",
            "142/142 [==============================] - 30s 214ms/step - loss: 0.2376 - accuracy: 0.9281 - val_loss: 0.6336 - val_accuracy: 0.8405\n",
            "Epoch 5/100\n",
            "142/142 [==============================] - 30s 215ms/step - loss: 0.1474 - accuracy: 0.9555 - val_loss: 0.6188 - val_accuracy: 0.8458\n",
            "Epoch 6/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0904 - accuracy: 0.9732 - val_loss: 0.6931 - val_accuracy: 0.8396\n",
            "Epoch 7/100\n",
            "142/142 [==============================] - 30s 211ms/step - loss: 0.0578 - accuracy: 0.9824 - val_loss: 0.7024 - val_accuracy: 0.8427\n",
            "Epoch 8/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0512 - accuracy: 0.9855 - val_loss: 0.7412 - val_accuracy: 0.8427\n",
            "Epoch 9/100\n",
            "142/142 [==============================] - 30s 214ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.7253 - val_accuracy: 0.8564\n",
            "Epoch 10/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.7535 - val_accuracy: 0.8568\n",
            "Epoch 11/100\n",
            "142/142 [==============================] - 30s 214ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.7324 - val_accuracy: 0.8652\n",
            "Epoch 12/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.7286 - val_accuracy: 0.8719\n",
            "Epoch 13/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.7413 - val_accuracy: 0.8701\n",
            "Epoch 14/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.7827 - val_accuracy: 0.8679\n",
            "Epoch 15/100\n",
            "142/142 [==============================] - 30s 212ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.8042 - val_accuracy: 0.8555\n",
            "Epoch 16/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0464 - accuracy: 0.9849 - val_loss: 0.8469 - val_accuracy: 0.8524\n",
            "Epoch 17/100\n",
            "142/142 [==============================] - 30s 211ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.9427 - val_accuracy: 0.8356\n",
            "Epoch 18/100\n",
            "142/142 [==============================] - 30s 212ms/step - loss: 0.0403 - accuracy: 0.9898 - val_loss: 0.8618 - val_accuracy: 0.8480\n",
            "Epoch 19/100\n",
            "142/142 [==============================] - 30s 213ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.8725 - val_accuracy: 0.8440\n",
            "Epoch 20/100\n",
            "142/142 [==============================] - 30s 211ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.8879 - val_accuracy: 0.8573\n",
            "Epoch 21/100\n",
            "142/142 [==============================] - 30s 210ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.8764 - val_accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "142/142 [==============================] - 30s 212ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.8972 - val_accuracy: 0.8546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6f5c2bafe0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_sequences, newsgroups_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr8d5g0WrNJw",
        "outputId": "b307da0f-bf0f-4f75-9a63-0745edc837c3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 10s 41ms/step - loss: 1.2652 - accuracy: 0.7811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2651829719543457, 0.781067430973053]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el accuracy en test es un poco inferior al de validación, y se encuentra cerca del 78%."
      ],
      "metadata": {
        "id": "BJyoXRPLbu3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Bidireccional"
      ],
      "metadata": {
        "id": "9PJCl3mqsynb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego se cambia el contextualizador (las capas convolucionales) por una LSTM bidireccional. En este caso se probaron los modos de \"sum y \"concat\", alcanzando unos accuracy de 0.8542 y 0.8586 respectivamente."
      ],
      "metadata": {
        "id": "mHgIUIqcsaVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Reshape\n",
        "from keras.layers import Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Bidirectional, LSTM, Activation\n",
        "import keras.backend as K\n",
        "from keras.activations import softmax\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "KESHvsQ6V85y"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros\n",
        "value_dim = 200\n",
        "nb_words = num_words\n",
        "\n",
        "K.clear_session()\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#lstm_out = Bidirectional(LSTM(value_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"sum\")(embedding_layer)\n",
        "lstm_out = Bidirectional(LSTM(value_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"concat\")(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(lstm_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(2*value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, 2*value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, lstm_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "dense1 = Dense(100, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(20, activation='softmax')(dense1)"
      ],
      "metadata": {
        "id": "nhlsFu18V6cS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model = Model(input_layer, dense2)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y3mk65WWSLt",
        "outputId": "4aa349e3-7ccb-4657-fcd0-c83e3094ec9c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 500)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 500, 300)             4024320   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 500, 400)             801600    ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 500, 1)               401       ['bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 500, 1)               0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, 500, 400, 1)          0         ['activation[0][0]']          \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 500, 400)             0         ['time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 500, 400)             0         ['reshape[0][0]',             \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 400)                  0         ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 100)                  40100     ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 20)                   2020      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41087321 (156.74 MB)\n",
            "Trainable params: 844121 (3.22 MB)\n",
            "Non-trainable params: 40243200 (153.52 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_sequences, newsgroups_train.target, batch_size=64, epochs=100, validation_split=0.2, callbacks=early_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LOSRosDWVb9",
        "outputId": "e9780f10-5c44-4e47-bdfd-88a7f36e41e4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "142/142 [==============================] - 26s 129ms/step - loss: 2.7120 - accuracy: 0.1198 - val_loss: 2.4405 - val_accuracy: 0.1463\n",
            "Epoch 2/100\n",
            "142/142 [==============================] - 15s 103ms/step - loss: 2.1238 - accuracy: 0.2770 - val_loss: 1.7438 - val_accuracy: 0.3937\n",
            "Epoch 3/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 1.4369 - accuracy: 0.4975 - val_loss: 1.1543 - val_accuracy: 0.6036\n",
            "Epoch 4/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.9971 - accuracy: 0.6685 - val_loss: 0.9173 - val_accuracy: 0.6832\n",
            "Epoch 5/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.7528 - accuracy: 0.7527 - val_loss: 0.7181 - val_accuracy: 0.7596\n",
            "Epoch 6/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.6077 - accuracy: 0.8016 - val_loss: 0.6635 - val_accuracy: 0.7852\n",
            "Epoch 7/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 0.5165 - accuracy: 0.8296 - val_loss: 0.6190 - val_accuracy: 0.7998\n",
            "Epoch 8/100\n",
            "142/142 [==============================] - 14s 101ms/step - loss: 0.4316 - accuracy: 0.8622 - val_loss: 0.5986 - val_accuracy: 0.8051\n",
            "Epoch 9/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 0.3735 - accuracy: 0.8781 - val_loss: 0.5778 - val_accuracy: 0.8224\n",
            "Epoch 10/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.3137 - accuracy: 0.8981 - val_loss: 0.5969 - val_accuracy: 0.8171\n",
            "Epoch 11/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 0.2694 - accuracy: 0.9134 - val_loss: 0.5930 - val_accuracy: 0.8294\n",
            "Epoch 12/100\n",
            "142/142 [==============================] - 14s 95ms/step - loss: 0.2183 - accuracy: 0.9305 - val_loss: 0.6024 - val_accuracy: 0.8255\n",
            "Epoch 13/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.1837 - accuracy: 0.9413 - val_loss: 0.5724 - val_accuracy: 0.8418\n",
            "Epoch 14/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.1492 - accuracy: 0.9528 - val_loss: 0.6318 - val_accuracy: 0.8352\n",
            "Epoch 15/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.1276 - accuracy: 0.9618 - val_loss: 0.6522 - val_accuracy: 0.8409\n",
            "Epoch 16/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0901 - accuracy: 0.9732 - val_loss: 0.6732 - val_accuracy: 0.8405\n",
            "Epoch 17/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0806 - accuracy: 0.9768 - val_loss: 0.6652 - val_accuracy: 0.8453\n",
            "Epoch 18/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 0.0687 - accuracy: 0.9832 - val_loss: 0.6721 - val_accuracy: 0.8493\n",
            "Epoch 19/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0668 - accuracy: 0.9811 - val_loss: 0.7305 - val_accuracy: 0.8445\n",
            "Epoch 20/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.7233 - val_accuracy: 0.8405\n",
            "Epoch 21/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.7814 - val_accuracy: 0.8427\n",
            "Epoch 22/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0438 - accuracy: 0.9892 - val_loss: 0.8172 - val_accuracy: 0.8352\n",
            "Epoch 23/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.7645 - val_accuracy: 0.8480\n",
            "Epoch 24/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.7879 - val_accuracy: 0.8502\n",
            "Epoch 25/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 0.8478 - val_accuracy: 0.8462\n",
            "Epoch 26/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.9031 - val_accuracy: 0.8427\n",
            "Epoch 27/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.8966 - val_accuracy: 0.8308\n",
            "Epoch 28/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0603 - accuracy: 0.9841 - val_loss: 0.7994 - val_accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.8558 - val_accuracy: 0.8484\n",
            "Epoch 30/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.8557 - val_accuracy: 0.8559\n",
            "Epoch 31/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.8979 - val_accuracy: 0.8489\n",
            "Epoch 32/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.9453 - val_accuracy: 0.8405\n",
            "Epoch 33/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 0.8747 - val_accuracy: 0.8462\n",
            "Epoch 34/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 0.8604 - val_accuracy: 0.8400\n",
            "Epoch 35/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 0.8606 - val_accuracy: 0.8458\n",
            "Epoch 36/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.8811 - val_accuracy: 0.8546\n",
            "Epoch 37/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.8573\n",
            "Epoch 38/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 8.4375e-04 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8564\n",
            "Epoch 39/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 5.9912e-04 - accuracy: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.8573\n",
            "Epoch 40/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 4.8085e-04 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8573\n",
            "Epoch 41/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 3.9560e-04 - accuracy: 1.0000 - val_loss: 0.9544 - val_accuracy: 0.8582\n",
            "Epoch 42/100\n",
            "142/142 [==============================] - 14s 98ms/step - loss: 3.3667e-04 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.8586\n",
            "Epoch 43/100\n",
            "142/142 [==============================] - 14s 96ms/step - loss: 2.8895e-04 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.8564\n",
            "Epoch 44/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 2.5266e-04 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.8568\n",
            "Epoch 45/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 2.2257e-04 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.8559\n",
            "Epoch 46/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.9780e-04 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.8542\n",
            "Epoch 47/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.7667e-04 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8555\n",
            "Epoch 48/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.5870e-04 - accuracy: 1.0000 - val_loss: 1.0176 - val_accuracy: 0.8559\n",
            "Epoch 49/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.4234e-04 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.8555\n",
            "Epoch 50/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.2865e-04 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.8555\n",
            "Epoch 51/100\n",
            "142/142 [==============================] - 14s 97ms/step - loss: 1.1666e-04 - accuracy: 1.0000 - val_loss: 1.0382 - val_accuracy: 0.8555\n",
            "Epoch 52/100\n",
            "142/142 [==============================] - 14s 99ms/step - loss: 1.0540e-04 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.8555\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6f52ac4820>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_sequences, newsgroups_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRoi5WdFWi4O",
        "outputId": "284bd8d5-6406-4665-e693-8087617299a5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 6s 27ms/step - loss: 1.7386 - accuracy: 0.7666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7386465072631836, 0.7665958404541016]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que esta red tiene una performance ligeramente inferior a la primera, y un tiempo de procesamiento similar, pues le lleva el doble de epochs en converger, pero cada epoch demora la mitad."
      ],
      "metadata": {
        "id": "BDzZg6nAfGqH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}